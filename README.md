````markdown
# IA au service de la qualitÃ© des donnÃ©es (POC)

Ce projet a pour objectif de proposer une **solution modulaire** pour dÃ©tecter les anomalies de qualitÃ© des donnÃ©es de maniÃ¨re rapide et intuitive, sans nÃ©cessiter la dÃ©finition manuelle de rÃ¨gles mÃ©tiers. Le moteur dâ€™analyse repose sur un systÃ¨me multi-agents IA (Azure AI Foundry) et sâ€™appuie sur un catalogue de donnÃ©es, un orchestrateur, un framework de tests, et un dashboard de restitution.


## Architecture du POC

```text
+-------------+    +-------------+    +-------------+    +--------------+
| Chatbot     | -> | Orchestrator| -> | AI Foundry  | -> | Great Expect.|
| (Streamlit) |    | (Airflow)   |    | (Azure)     |    | (Runner)     |
+-------------+    +-------------+    +-------------+    +--------------+
       |                                                           |
       v                                                           v
 +----------------+                                        +--------------+
 | Data Lakehouse |                                        | Power BI     |
 | (MS Fabric)    |                                        | Dashboard    |
 +----------------+                                        +--------------+
       |                                                           ^
       v                                                           |
 +----------------+                                             |
 | Data Catalog   | <-------------------------------------------+
 | (Data Hub)     |
 +----------------+
````

**Technologies clÃ©s**:

* Chatbot API : Python (FastAPI) + Streamlit UI
* Orchestration : Apache Airflow
* Catalogue de mÃ©tadonnÃ©es : Data Hub (MCP)
* Moteur IA : Azure AI Foundry multi-agents
* ExÃ©cution rÃ¨gles : Great Expectations
* Reporting : Power BI (API REST)
* CI/CD & Infra : Docker, Terraform, azure-pipelines

## FonctionnalitÃ©s (Epics & User Stories)

### Epic 1 : Initialisation via le chatbot

* **US1** : SÃ©lection de lâ€™asset (nom/chemin)
* **US2** : Saisie des credentials 
* **US3** : Validation des informations saisies
* **US4** : Lancement du scan et rÃ©ception dâ€™un jobId

### Epic 2 : Orchestration & collecte des mÃ©tadonnÃ©es

* **US5** : RÃ©ception du job par Airflow
* **US6** : Connexion Ã  la source et rÃ©cupÃ©ration de lâ€™asset
* **US7** : Scan schÃ©ma & profilage des donnÃ©es
* **US8** : Ingestion des mÃ©tadonnÃ©es dans Data Hub

### Epic 3 : GÃ©nÃ©ration & stockage des rÃ¨gles mÃ©tiers

* **US9** : RÃ©cupÃ©ration des mÃ©tadonnÃ©es
* **US10** : RÃ©cupÃ©ration de lâ€™asset pour contexte
* **US11** : GÃ©nÃ©ration automatique des expectations
* **US12** : Stockage et versioning des rÃ¨gles
* **US13** : Publication pour feedback utilisateur

### Epic 4 : ExÃ©cution des contrÃ´les & restitution

* **US14** : ExÃ©cution des expectations (GE Runner)
* **US15** : Collecte des enregistrements non-conformes
* **US16** : Analyse et explication des anomalies
* **US17** : Stockage historique des anomalies
* **US18** : Publication dans Power BI
* **US19** : SynthÃ¨se & notification via le chatbot

### Epic 5 : Industrialisation, maintenance et gouvernance

* **US20** : Pipeline CI/CD (build, tests, Docker)
* **US21** : DÃ©ploiement IaC (Terraform)
* **US25** : Gestion centralisÃ©e des secrets

## PrÃ©requis

* Python 3.9+
* Docker & Docker Compose
* AccÃ¨s Ã  un workspace Azure et Data Hub
* Compte Power BI avec permissions dâ€™API

## Installation & Mise en route

> **ðŸš§ En cours dâ€™implÃ©mentation**


## Roadmap & Prochaines Ã‰tapes

1. **Phase de prototypage** : US1â€“US4 (Chatbot minimal + Orchestration)
2. **Phase IA & rÃ¨gles** : US5â€“US13 (Multi-agents + Great Expectations)
3. **Phase restitution** : US14â€“US19 (Power BI + SynthÃ¨se chatbot)
4. **Industrialisation** : CI/CD, monitoring, sÃ©curitÃ©


```
